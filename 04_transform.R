# # Transforming Data 

# At the end of the last module, we saw some examples of `select()` and `distinct()`.
# These are examples of dplyr *verbs*.
# In this module we will look at the most common dplyr verbs, and
# understand how they work in sparklyr and how they can be used
# together to perform data manipulation tasks.


# ## Setup

library(sparklyr)
library(dplyr)

spark <- spark_connect(master = "local", app_name = "inspect")


# ## Load the riders data from HDFS into a Spark DataFrame

riders <- spark_read_csv(
  sc = spark,
  name = "riders",
  path = "/duocar/raw/riders/"
)


# ## Using dplyr verbs

# ### Background about dplyr verbs

# dplyr provides a set of *verbs* to perform the most common data manipulation tasks.
# The main dplyr verbs are:
# * `select()` to select columns
# * `filter()` to filter rows
# * `arrange()` to order rows
# * `mutate()` to create new columns
# * `summarise()` to aggregate
# * `group_by()` to define groups of rows

# `group_by()` is not exactly a verb, but a function that 
# can be used to modify the behavior of other verbs.

# dplyr verbs work on local data frames in R memory.
# Most R users are familiar with this.

# For example: Calculate the rounded average sepal width of iris flowers by species
# after removing some outlying values, and return the results in increasing order

avg_sepal_width <- iris %>%
  select(Sepal.Width, Species) %>%
  filter(Sepal.Width > 2 & Sepal.Width < 4.0) %>%
  group_by(Species) %>%
  summarise(Avg.Sepal.Width = mean(Sepal.Width)) %>%
  arrange(Avg.Sepal.Width) %>%
  mutate(Avg.Sepal.Width = round(Avg.Sepal.Width, 1))

# Print the result:

avg_sepal_width

# Many R users have used dplyr in this way.


# ### dplyr verbs with sparklyr

# dplyr verbs also work on Spark data frames.
# sparklyr enables this; it provides a backend to dplyr for Spark.

# For example: load the iris flower data into Spark,
# and repeat the same dplyr example as above.

iris_spark <- sdf_copy_to(spark, iris)

avg_sepal_width_spark <- iris_spark %>%
  select(Sepal_Width, Species) %>%
  filter(Sepal_Width > 2.0 & Sepal_Width < 4.0) %>%
  group_by(Species) %>%
  summarise(Avg_Sepal_Width = mean(Sepal_Width)) %>%
  arrange(Avg_Sepal_Width) %>%
  mutate(Avg_Sepal_Width = round(Avg_Sepal_Width, 1))

# This is the same as the example above, except periods in column names are replaced by underscores
# Because sparklyr automatically renames columns, replacing periods with underscores.

# The result is the same as in the example above:

avg_sepal_width_spark


# ### SQL Translation

# sparklyr (with dplyr and dbplyr) calculated the above result
# by translating the series of verbs into a SQL statement.

# To see the SQL statement, use `show_query()`:

avg_sepal_width_spark %>% show_query()

# Note that SQL statements generated by dplyr backends 
# sometimes contain unnecessary subqueries.


# If you prefer to directly write and issue SQL queries, you can:

tbl(spark, sql("SELECT Species, round(avg(Sepal_Width), 1) AS Avg_Sepal_Width 
FROM iris 
WHERE Sepal_Width > 2.0 AND Sepal_Width < 4.0
GROUP BY 
Species ORDER BY Avg_Sepal_Width"))

# R users typically find it more intuitive to use dplyr verbs
# instead of directly writing SQL statements.


# ## Simple dplyr examples

# These examples use only one dplyr verb at a time, to highlight what each verb does.

# ### `select()`

# `select()` selects one or more columns

riders %>% select(first_name)

riders %>% select(first_name, last_name)

# You can also use `select()` to remove columns:

riders %>% select(-first_name)

riders %>% select(-c(first_name, last_name))

# And you can use several functions inside `select()`,
# including `starts_with()`, `ends_with()`, `contains()`,
# and `matches()`:

riders %>% select(ends_with("_name"))

riders %>% select(-ends_with("_name"))

# For more details about the functions you can use inside
# `select()` see `?select_helpers`.

# You can also refer to columns by their numeric positions:

riders %>% select(4:5)

riders %>% select(-(4:5))


# There are several variations on `select()`:

# `distinct()` works like `select()`
# but it reutrns only distinct values

riders %>% distinct(first_name)

riders %>% distinct(first_name, last_name)

# `pull()` is like `select()` for a single column, 
# but it returns a vector instead of a `tbl`:

riders %>% select(first_name)

riders %>% pull(first_name)

# You can use `select()` to rename columns, but it only keeps
# the columns you specify:

riders %>% select(fname = first_name, lname = last_name)

# To rename some columns while keeping all other columns, 
# use `rename()` instead of `select()`:

# Unfortunately this throws an error due to some bug:
#riders %>% rename(fname = first_name, lname = last_name)

# Workaround: Rename the columns one at a time:
riders %>% 
  rename(fname = first_name) %>%
  rename(lname = last_name)


# ### `filter()` filters rows of data by one or more conditions

riders %>% filter(first_name == "Skylar")

# To filter by more than one condition, you can use `&` 
# or list the conditions separated by commas

riders %>% filter(first_name == "Skylar", sex == "female")

riders %>% filter(first_name == "Skylar" & sex == "female")

# And you can use other logical operators like `|`:

riders %>% filter(first_name == "Skylar" | last_name == "Hayes")


# ### `arrange()` orders the rows of the data by the values of variables

riders %>% arrange(birth_date)

riders %>% arrange(last_name, first_name)

# The default sort order is ascending.
# Use `desc()` to sort in descending order:

riders %>% arrange(desc(birth_date))


# ### `mutate()` ... 

# ...

# A variation on `mutate()` is `transmute()` ...

# ...


# ### `summarise()` ...

# ...

# You can also use the American English spelling: `summarize()` (z instead of s)


# ### `group_by()` ...

# ...



# ## Cleanup

spark_disconnect(spark)