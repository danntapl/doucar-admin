<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head><title>R: R Interface to Apache Spark</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>
<h1> R Interface to Apache Spark
<img class="toplogo" src="../../../doc/html/Rlogo.svg" alt="[R logo]" />
</h1>
<hr/>
<div style="text-align: center;">
<a href="../../../doc/html/packages.html"><img class="arrow" src="../../../doc/html/left.jpg" alt="[Up]" /></a>
<a href="../../../doc/html/index.html"><img class="arrow" src="../../../doc/html/up.jpg" alt="[Top]" /></a>
</div><h2>Documentation for package &lsquo;sparklyr&rsquo; version 0.6.4</h2>

<ul><li><a href="../DESCRIPTION">DESCRIPTION file</a>.</li>
</ul>

<h2>Help Pages</h2>


<p style="text-align: center;">
<a href="#A">A</a>
<a href="#C">C</a>
<a href="#D">D</a>
<a href="#E">E</a>
<a href="#F">F</a>
<a href="#G">G</a>
<a href="#H">H</a>
<a href="#I">I</a>
<a href="#J">J</a>
<a href="#L">L</a>
<a href="#M">M</a>
<a href="#N">N</a>
<a href="#R">R</a>
<a href="#S">S</a>
<a href="#T">T</a>
</p>


<h2><a name="A">-- A --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="ml_glm_tidiers.html">augment.ml_model_generalized_linear_regression</a></td>
<td>Tidying methods for Spark ML linear models</td></tr>
<tr><td style="width: 25%;"><a href="ml_glm_tidiers.html">augment.ml_model_linear_regression</a></td>
<td>Tidying methods for Spark ML linear models</td></tr>
</table>

<h2><a name="C">-- C --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="checkpoint_directory.html">checkpoint_directory</a></td>
<td>Set/Get Spark checkpoint directory</td></tr>
<tr><td style="width: 25%;"><a href="compile_package_jars.html">compile_package_jars</a></td>
<td>Compile Scala sources into a Java Archive (jar)</td></tr>
<tr><td style="width: 25%;"><a href="connection_config.html">connection_config</a></td>
<td>Read configuration values for a connection</td></tr>
<tr><td style="width: 25%;"><a href="copy_to.spark_connection.html">copy_to.spark_connection</a></td>
<td>Copy an R Data Frame to Spark</td></tr>
</table>

<h2><a name="D">-- D --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="download_scalac.html">download_scalac</a></td>
<td>Downloads default Scala Compilers</td></tr>
</table>

<h2><a name="E">-- E --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="ensure.html">ensure</a></td>
<td>Enforce Specific Structure for R Objects</td></tr>
<tr><td style="width: 25%;"><a href="ensure.html">ensure_scalar_boolean</a></td>
<td>Enforce Specific Structure for R Objects</td></tr>
<tr><td style="width: 25%;"><a href="ensure.html">ensure_scalar_character</a></td>
<td>Enforce Specific Structure for R Objects</td></tr>
<tr><td style="width: 25%;"><a href="ensure.html">ensure_scalar_double</a></td>
<td>Enforce Specific Structure for R Objects</td></tr>
<tr><td style="width: 25%;"><a href="ensure.html">ensure_scalar_integer</a></td>
<td>Enforce Specific Structure for R Objects</td></tr>
</table>

<h2><a name="F">-- F --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="find_scalac.html">find_scalac</a></td>
<td>Discover the Scala Compiler</td></tr>
<tr><td style="width: 25%;"><a href="ft_binarizer.html">ft_binarizer</a></td>
<td>Feature Transformation - Binarizer</td></tr>
<tr><td style="width: 25%;"><a href="ft_bucketizer.html">ft_bucketizer</a></td>
<td>Feature Transformation - Bucketizer</td></tr>
<tr><td style="width: 25%;"><a href="ft_count_vectorizer.html">ft_count_vectorizer</a></td>
<td>Feature Tranformation - CountVectorizer</td></tr>
<tr><td style="width: 25%;"><a href="ft_discrete_cosine_transform.html">ft_discrete_cosine_transform</a></td>
<td>Feature Transformation - Discrete Cosine Transform (DCT)</td></tr>
<tr><td style="width: 25%;"><a href="ft_elementwise_product.html">ft_elementwise_product</a></td>
<td>Feature Transformation - ElementwiseProduct</td></tr>
<tr><td style="width: 25%;"><a href="ft_index_to_string.html">ft_index_to_string</a></td>
<td>Feature Transformation - IndexToString</td></tr>
<tr><td style="width: 25%;"><a href="ft_one_hot_encoder.html">ft_one_hot_encoder</a></td>
<td>Feature Transformation - OneHotEncoder</td></tr>
<tr><td style="width: 25%;"><a href="ft_quantile_discretizer.html">ft_quantile_discretizer</a></td>
<td>Feature Transformation - QuantileDiscretizer</td></tr>
<tr><td style="width: 25%;"><a href="ft_regex_tokenizer.html">ft_regex_tokenizer</a></td>
<td>Feature Tranformation - RegexTokenizer</td></tr>
<tr><td style="width: 25%;"><a href="ft_sql_transformer.html">ft_sql_transformer</a></td>
<td>Feature Transformation - SQLTransformer</td></tr>
<tr><td style="width: 25%;"><a href="ft_stop_words_remover.html">ft_stop_words_remover</a></td>
<td>Feature Tranformation - StopWordsRemover</td></tr>
<tr><td style="width: 25%;"><a href="ft_string_indexer.html">ft_string_indexer</a></td>
<td>Feature Transformation - StringIndexer</td></tr>
<tr><td style="width: 25%;"><a href="ft_tokenizer.html">ft_tokenizer</a></td>
<td>Feature Tranformation - Tokenizer</td></tr>
<tr><td style="width: 25%;"><a href="ft_vector_assembler.html">ft_vector_assembler</a></td>
<td>Feature Transformation - VectorAssembler</td></tr>
</table>

<h2><a name="G">-- G --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="ml_glm_tidiers.html">glance.ml_model_generalized_linear_regression</a></td>
<td>Tidying methods for Spark ML linear models</td></tr>
<tr><td style="width: 25%;"><a href="ml_glm_tidiers.html">glance.ml_model_linear_regression</a></td>
<td>Tidying methods for Spark ML linear models</td></tr>
</table>

<h2><a name="H">-- H --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="spark-api.html">hive_context</a></td>
<td>Access the Spark API</td></tr>
<tr><td style="width: 25%;"><a href="hive_context_config.html">hive_context_config</a></td>
<td>Runtime configuration interface for Hive</td></tr>
</table>

<h2><a name="I">-- I --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="invoke.html">invoke</a></td>
<td>Invoke a Method on a JVM Object</td></tr>
<tr><td style="width: 25%;"><a href="invoke.html">invoke_new</a></td>
<td>Invoke a Method on a JVM Object</td></tr>
<tr><td style="width: 25%;"><a href="invoke.html">invoke_static</a></td>
<td>Invoke a Method on a JVM Object</td></tr>
</table>

<h2><a name="J">-- J --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="spark-api.html">java_context</a></td>
<td>Access the Spark API</td></tr>
</table>

<h2><a name="L">-- L --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="livy_config.html">livy_config</a></td>
<td>Create a Spark Configuration for Livy</td></tr>
<tr><td style="width: 25%;"><a href="livy_service.html">livy_service_start</a></td>
<td>Start Livy</td></tr>
<tr><td style="width: 25%;"><a href="livy_service.html">livy_service_stop</a></td>
<td>Start Livy</td></tr>
</table>

<h2><a name="M">-- M --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="ml_als_factorization.html">ml_als_factorization</a></td>
<td>Spark ML - Alternating Least Squares (ALS) matrix factorization.</td></tr>
<tr><td style="width: 25%;"><a href="ml_binary_classification_eval.html">ml_binary_classification_eval</a></td>
<td>Spark ML - Binary Classification Evaluator</td></tr>
<tr><td style="width: 25%;"><a href="ml_classification_eval.html">ml_classification_eval</a></td>
<td>Spark ML - Classification Evaluator</td></tr>
<tr><td style="width: 25%;"><a href="ml_create_dummy_variables.html">ml_create_dummy_variables</a></td>
<td>Create Dummy Variables</td></tr>
<tr><td style="width: 25%;"><a href="ml_decision_tree.html">ml_decision_tree</a></td>
<td>Spark ML - Decision Trees</td></tr>
<tr><td style="width: 25%;"><a href="ml_generalized_linear_regression.html">ml_generalized_linear_regression</a></td>
<td>Spark ML - Generalized Linear Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_glm_tidiers.html">ml_glm_tidiers</a></td>
<td>Tidying methods for Spark ML linear models</td></tr>
<tr><td style="width: 25%;"><a href="ml_gradient_boosted_trees.html">ml_gradient_boosted_trees</a></td>
<td>Spark ML - Gradient-Boosted Tree</td></tr>
<tr><td style="width: 25%;"><a href="ml_kmeans.html">ml_kmeans</a></td>
<td>Spark ML - K-Means Clustering</td></tr>
<tr><td style="width: 25%;"><a href="ml_lda.html">ml_lda</a></td>
<td>Spark ML - Latent Dirichlet Allocation</td></tr>
<tr><td style="width: 25%;"><a href="ml_linear_regression.html">ml_linear_regression</a></td>
<td>Spark ML - Linear Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_saveload.html">ml_load</a></td>
<td>Save / Load a Spark ML Model Fit</td></tr>
<tr><td style="width: 25%;"><a href="ml_logistic_regression.html">ml_logistic_regression</a></td>
<td>Spark ML - Logistic Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_model.html">ml_model</a></td>
<td>Create an ML Model Object</td></tr>
<tr><td style="width: 25%;"><a href="ml_model_data.html">ml_model_data</a></td>
<td>Extracts data associated with a Spark ML model</td></tr>
<tr><td style="width: 25%;"><a href="ml_multilayer_perceptron.html">ml_multilayer_perceptron</a></td>
<td>Spark ML - Multilayer Perceptron</td></tr>
<tr><td style="width: 25%;"><a href="ml_naive_bayes.html">ml_naive_bayes</a></td>
<td>Spark ML - Naive-Bayes</td></tr>
<tr><td style="width: 25%;"><a href="ml_one_vs_rest.html">ml_one_vs_rest</a></td>
<td>Spark ML - One vs Rest</td></tr>
<tr><td style="width: 25%;"><a href="ml_options.html">ml_options</a></td>
<td>Options for Spark ML Routines</td></tr>
<tr><td style="width: 25%;"><a href="ml_pca.html">ml_pca</a></td>
<td>Spark ML - Principal Components Analysis</td></tr>
<tr><td style="width: 25%;"><a href="ml_prepare_dataframe.html">ml_prepare_dataframe</a></td>
<td>Prepare a Spark DataFrame for Spark ML Routines</td></tr>
<tr><td style="width: 25%;"><a href="ml_prepare_inputs.html">ml_prepare_features</a></td>
<td>Pre-process the Inputs to a Spark ML Routine</td></tr>
<tr><td style="width: 25%;"><a href="ml_prepare_inputs.html">ml_prepare_inputs</a></td>
<td>Pre-process the Inputs to a Spark ML Routine</td></tr>
<tr><td style="width: 25%;"><a href="ml_prepare_inputs.html">ml_prepare_response_features_intercept</a></td>
<td>Pre-process the Inputs to a Spark ML Routine</td></tr>
<tr><td style="width: 25%;"><a href="ml_random_forest.html">ml_random_forest</a></td>
<td>Spark ML - Random Forests</td></tr>
<tr><td style="width: 25%;"><a href="ml_saveload.html">ml_save</a></td>
<td>Save / Load a Spark ML Model Fit</td></tr>
<tr><td style="width: 25%;"><a href="ml_saveload.html">ml_saveload</a></td>
<td>Save / Load a Spark ML Model Fit</td></tr>
<tr><td style="width: 25%;"><a href="ml_survival_regression.html">ml_survival_regression</a></td>
<td>Spark ML - Survival Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_feature_importance.html">ml_tree_feature_importance</a></td>
<td>Spark ML - Feature Importance for Tree Models</td></tr>
</table>

<h2><a name="N">-- N --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="na.replace.html">na.replace</a></td>
<td>Replace Missing Values in Objects</td></tr>
</table>

<h2><a name="R">-- R --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="register_extension.html">registered_extensions</a></td>
<td>Register a Package that Implements a Spark Extension</td></tr>
<tr><td style="width: 25%;"><a href="register_extension.html">register_extension</a></td>
<td>Register a Package that Implements a Spark Extension</td></tr>
</table>

<h2><a name="S">-- S --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="sdf-saveload.html">sdf-saveload</a></td>
<td>Save / Load a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_along.html">sdf_along</a></td>
<td>Create DataFrame for along Object</td></tr>
<tr><td style="width: 25%;"><a href="sdf_bind.html">sdf_bind</a></td>
<td>Bind multiple Spark DataFrames by row and column</td></tr>
<tr><td style="width: 25%;"><a href="sdf_bind.html">sdf_bind_cols</a></td>
<td>Bind multiple Spark DataFrames by row and column</td></tr>
<tr><td style="width: 25%;"><a href="sdf_bind.html">sdf_bind_rows</a></td>
<td>Bind multiple Spark DataFrames by row and column</td></tr>
<tr><td style="width: 25%;"><a href="sdf_broadcast.html">sdf_broadcast</a></td>
<td>Broadcast hint</td></tr>
<tr><td style="width: 25%;"><a href="sdf_checkpoint.html">sdf_checkpoint</a></td>
<td>Checkpoint a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_coalesce.html">sdf_coalesce</a></td>
<td>Coalesces a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_copy_to.html">sdf_copy_to</a></td>
<td>Copy an Object into Spark</td></tr>
<tr><td style="width: 25%;"><a href="sdf_dim.html">sdf_dim</a></td>
<td>Support for Dimension Operations</td></tr>
<tr><td style="width: 25%;"><a href="sdf_copy_to.html">sdf_import</a></td>
<td>Copy an Object into Spark</td></tr>
<tr><td style="width: 25%;"><a href="sdf_last_index.html">sdf_last_index</a></td>
<td>Returns the last index of a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_len.html">sdf_len</a></td>
<td>Create DataFrame for Length</td></tr>
<tr><td style="width: 25%;"><a href="sdf-saveload.html">sdf_load_parquet</a></td>
<td>Save / Load a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf-saveload.html">sdf_load_table</a></td>
<td>Save / Load a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_mutate.html">sdf_mutate</a></td>
<td>Mutate a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_mutate.html">sdf_mutate_</a></td>
<td>Mutate a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_dim.html">sdf_ncol</a></td>
<td>Support for Dimension Operations</td></tr>
<tr><td style="width: 25%;"><a href="sdf_dim.html">sdf_nrow</a></td>
<td>Support for Dimension Operations</td></tr>
<tr><td style="width: 25%;"><a href="sdf_num_partitions.html">sdf_num_partitions</a></td>
<td>Gets number of partitions of a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_partition.html">sdf_partition</a></td>
<td>Partition a Spark Dataframe</td></tr>
<tr><td style="width: 25%;"><a href="sdf_persist.html">sdf_persist</a></td>
<td>Persist a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_pivot.html">sdf_pivot</a></td>
<td>Pivot a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_predict.html">sdf_predict</a></td>
<td>Model Predictions with Spark DataFrames</td></tr>
<tr><td style="width: 25%;"><a href="sdf_project.html">sdf_project</a></td>
<td>Project features onto principal components</td></tr>
<tr><td style="width: 25%;"><a href="sdf_quantile.html">sdf_quantile</a></td>
<td>Compute (Approximate) Quantiles with a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_read_column.html">sdf_read_column</a></td>
<td>Read a Column from a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_register.html">sdf_register</a></td>
<td>Register a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_repartition.html">sdf_repartition</a></td>
<td>Repartition a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_residuals.html">sdf_residuals</a></td>
<td>Model Residuals</td></tr>
<tr><td style="width: 25%;"><a href="sdf_residuals.html">sdf_residuals.ml_model_generalized_linear_regression</a></td>
<td>Model Residuals</td></tr>
<tr><td style="width: 25%;"><a href="sdf_residuals.html">sdf_residuals.ml_model_linear_regression</a></td>
<td>Model Residuals</td></tr>
<tr><td style="width: 25%;"><a href="sdf_sample.html">sdf_sample</a></td>
<td>Randomly Sample Rows from a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf-saveload.html">sdf_save_parquet</a></td>
<td>Save / Load a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf-saveload.html">sdf_save_table</a></td>
<td>Save / Load a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_schema.html">sdf_schema</a></td>
<td>Read the Schema of a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_separate_column.html">sdf_separate_column</a></td>
<td>Separate a Vector Column into Scalar Columns</td></tr>
<tr><td style="width: 25%;"><a href="sdf_seq.html">sdf_seq</a></td>
<td>Create DataFrame for Range</td></tr>
<tr><td style="width: 25%;"><a href="sdf_sort.html">sdf_sort</a></td>
<td>Sort a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_with_sequential_id.html">sdf_with_sequential_id</a></td>
<td>Add a Sequential ID Column to a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_with_unique_id.html">sdf_with_unique_id</a></td>
<td>Add a Unique ID Column to a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="spark-api.html">spark-api</a></td>
<td>Access the Spark API</td></tr>
<tr><td style="width: 25%;"><a href="spark-connections.html">spark-connections</a></td>
<td>Manage Spark Connections</td></tr>
<tr><td style="width: 25%;"><a href="spark_apply.html">spark_apply</a></td>
<td>Apply an R Function in Spark</td></tr>
<tr><td style="width: 25%;"><a href="spark_apply_bundle.html">spark_apply_bundle</a></td>
<td>Create Bundle for Spark Apply</td></tr>
<tr><td style="width: 25%;"><a href="spark_apply_log.html">spark_apply_log</a></td>
<td>Log Writter for Spark Apply</td></tr>
<tr><td style="width: 25%;"><a href="spark_compilation_spec.html">spark_compilation_spec</a></td>
<td>Define a Spark Compilation Specification</td></tr>
<tr><td style="width: 25%;"><a href="spark_config.html">spark_config</a></td>
<td>Read Spark Configuration</td></tr>
<tr><td style="width: 25%;"><a href="spark-connections.html">spark_connect</a></td>
<td>Manage Spark Connections</td></tr>
<tr><td style="width: 25%;"><a href="spark_connection.html">spark_connection</a></td>
<td>Retrieve the Spark Connection Associated with an R Object</td></tr>
<tr><td style="width: 25%;"><a href="spark-connections.html">spark_connection_is_open</a></td>
<td>Manage Spark Connections</td></tr>
<tr><td style="width: 25%;"><a href="spark-api.html">spark_context</a></td>
<td>Access the Spark API</td></tr>
<tr><td style="width: 25%;"><a href="spark_context_config.html">spark_context_config</a></td>
<td>Runtime configuration interface for Spark.</td></tr>
<tr><td style="width: 25%;"><a href="spark_dataframe.html">spark_dataframe</a></td>
<td>Retrieve a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="spark_default_compilation_spec.html">spark_default_compilation_spec</a></td>
<td>Default Compilation Specification for Spark Extensions</td></tr>
<tr><td style="width: 25%;"><a href="spark_dependency.html">spark_dependency</a></td>
<td>Define a Spark dependency</td></tr>
<tr><td style="width: 25%;"><a href="spark-connections.html">spark_disconnect</a></td>
<td>Manage Spark Connections</td></tr>
<tr><td style="width: 25%;"><a href="spark-connections.html">spark_disconnect_all</a></td>
<td>Manage Spark Connections</td></tr>
<tr><td style="width: 25%;"><a href="checkpoint_directory.html">spark_get_checkpoint_dir</a></td>
<td>Set/Get Spark checkpoint directory</td></tr>
<tr><td style="width: 25%;"><a href="spark_home_set.html">spark_home_set</a></td>
<td>Set the SPARK_HOME environment variable</td></tr>
<tr><td style="width: 25%;"><a href="spark_install_sync.html">spark_install_sync</a></td>
<td>helper function to sync sparkinstall project to sparklyr</td></tr>
<tr><td style="width: 25%;"><a href="spark_jobj.html">spark_jobj</a></td>
<td>Retrieve a Spark JVM Object Reference</td></tr>
<tr><td style="width: 25%;"><a href="spark_load_table.html">spark_load_table</a></td>
<td>Reads from a Spark Table into a Spark DataFrame.</td></tr>
<tr><td style="width: 25%;"><a href="spark_log.html">spark_log</a></td>
<td>View Entries in the Spark Log</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_csv.html">spark_read_csv</a></td>
<td>Read a CSV file into a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_jdbc.html">spark_read_jdbc</a></td>
<td>Read from JDBC connection into a Spark DataFrame.</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_json.html">spark_read_json</a></td>
<td>Read a JSON file into a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_parquet.html">spark_read_parquet</a></td>
<td>Read a Parquet file into a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_source.html">spark_read_source</a></td>
<td>Read from a generic source into a Spark DataFrame.</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_table.html">spark_read_table</a></td>
<td>Reads from a Spark Table into a Spark DataFrame.</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_text.html">spark_read_text</a></td>
<td>Read a Text file into a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="spark_save_table.html">spark_save_table</a></td>
<td>Saves a Spark DataFrame as a Spark table</td></tr>
<tr><td style="width: 25%;"><a href="spark-api.html">spark_session</a></td>
<td>Access the Spark API</td></tr>
<tr><td style="width: 25%;"><a href="checkpoint_directory.html">spark_set_checkpoint_dir</a></td>
<td>Set/Get Spark checkpoint directory</td></tr>
<tr><td style="width: 25%;"><a href="spark_table_name.html">spark_table_name</a></td>
<td>Generate a Table Name from Expression</td></tr>
<tr><td style="width: 25%;"><a href="spark_version.html">spark_version</a></td>
<td>Get the Spark Version Associated with a Spark Connection</td></tr>
<tr><td style="width: 25%;"><a href="spark_version_from_home.html">spark_version_from_home</a></td>
<td>Get the Spark Version Associated with a Spark Installation</td></tr>
<tr><td style="width: 25%;"><a href="spark_web.html">spark_web</a></td>
<td>Open the Spark web interface</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_csv.html">spark_write_csv</a></td>
<td>Write a Spark DataFrame to a CSV</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_jdbc.html">spark_write_jdbc</a></td>
<td>Writes a Spark DataFrame into a JDBC table</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_json.html">spark_write_json</a></td>
<td>Write a Spark DataFrame to a JSON file</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_parquet.html">spark_write_parquet</a></td>
<td>Write a Spark DataFrame to a Parquet file</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_source.html">spark_write_source</a></td>
<td>Writes a Spark DataFrame into a generic source</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_table.html">spark_write_table</a></td>
<td>Writes a Spark DataFrame into a Spark table</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_text.html">spark_write_text</a></td>
<td>Write a Spark DataFrame to a Text file</td></tr>
<tr><td style="width: 25%;"><a href="src_databases.html">src_databases</a></td>
<td>Show database list</td></tr>
</table>

<h2><a name="T">-- T --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="tbl_cache.html">tbl_cache</a></td>
<td>Cache a Spark Table</td></tr>
<tr><td style="width: 25%;"><a href="tbl_change_db.html">tbl_change_db</a></td>
<td>Use specific database</td></tr>
<tr><td style="width: 25%;"><a href="tbl_uncache.html">tbl_uncache</a></td>
<td>Uncache a Spark Table</td></tr>
<tr><td style="width: 25%;"><a href="ml_glm_tidiers.html">tidy.ml_model_generalized_linear_regression</a></td>
<td>Tidying methods for Spark ML linear models</td></tr>
<tr><td style="width: 25%;"><a href="ml_glm_tidiers.html">tidy.ml_model_linear_regression</a></td>
<td>Tidying methods for Spark ML linear models</td></tr>
</table>
</body></html>
